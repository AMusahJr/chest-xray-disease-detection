{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8dc9b6-83c1-45fe-ae68-39b46f155d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: Set project root for src imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc21242-ca63-4cf0-9cbd-1de5de2fa7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3872755b-3851-4f54-9df7-5c2c8f1977b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 :Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44f91c3-29c3-463e-8b29-5b37cbdac1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "from src.dataset import ChestXrayDataset\n",
    "from src.model import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97d04faa-5907-4f09-9675-9df95cff3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Step 2 : Device Setup\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493d23d6-98e9-419b-b503-848de1009a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Transforms $ Datasets\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = ChestXrayDataset(\n",
    "    csv_file=\"../data/processed/train_small.csv\",\n",
    "    image_dir=\"../data/images\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = ChestXrayDataset(\n",
    "    csv_file=\"../data/processed/val_small.csv\",\n",
    "    image_dir=\"../data/images\",\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "batch_size = 16  # increase for speed\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c4f10e9-1ef3-42ab-8b94-1d08d41f3ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, criterion, and optimizer ready!\n",
      "pos_weight: 82.93803405761719\n"
     ]
    }
   ],
   "source": [
    "# Step 4 : Model, Loss, Optimizer\n",
    "model = get_model(pretrained=True).to(device)\n",
    "\n",
    "# Handle class imbalance\n",
    "train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "pos = train_df[\"Pneumonia\"].sum()\n",
    "neg = len(train_df) - pos\n",
    "\n",
    "# MPS requires float32\n",
    "pos_weight = torch.tensor(neg / pos, dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"Model, criterion, and optimizer ready!\")\n",
    "print(\"pos_weight:\", pos_weight.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "886fbfd7-f889-4da7-a543-e4ab506a7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 : Metrics\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute AUC, sensitivity, specificity for binary classification.\n",
    "    \"\"\"\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_bin).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return auc, sensitivity, specificity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e223ab6-3141-4af6-a146-95266b86f1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   2%|▌                      | 28/1250 [00:24<17:39,  1.15it/s]"
     ]
    }
   ],
   "source": [
    "# Step 6 : Training & Validation Loop\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        imgs, labels = imgs.to(device), labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1}, Training Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20e614e1-0fa8-470e-98b4-8a7cc97a0c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - AUC: 0.593, Sensitivity: 0.075, Specificity: 0.912\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # ---- Validation ----\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.float().to(device)\n",
    "        outputs = model(imgs).squeeze(1)\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "auc, sens, spec = compute_metrics(np.array(all_labels), np.array(all_preds))\n",
    "print(f\"Validation - AUC: {auc:.3f}, Sensitivity: {sens:.3f}, Specificity: {spec:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c6a07b0-4e76-4f8d-abbb-1e93bf0aca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to results/resnet50_pneumonia.pt\n"
     ]
    }
   ],
   "source": [
    "# Step 7 : Save Model\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../results/resnet50_pneumonia.pt\")\n",
    "print(\"Model saved to results/resnet50_pneumonia.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b139c-9239-4648-81d8-e21a56eddd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81684154-ceef-4713-a73d-a41bce1153cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|███████████████████████████| 1250/1250 [41:30<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Train Loss: 1.4857\n",
      "Val AUC: 0.5501 | Sensitivity: 0.6866 | Specificity: 0.3671\n",
      "✅ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|█████████████████████████| 1250/1250 [2:06:42<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Train Loss: 1.3513\n",
      "Val AUC: 0.5808 | Sensitivity: 0.5373 | Specificity: 0.6422\n",
      "✅ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████| 1250/1250 [52:54<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Train Loss: 1.3568\n",
      "Val AUC: 0.5269 | Sensitivity: 0.4179 | Specificity: 0.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|█████████████████████████| 1250/1250 [2:33:34<00:00,  7.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Train Loss: 1.3999\n",
      "Val AUC: 0.5710 | Sensitivity: 0.5522 | Specificity: 0.6104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|█████████████████████████| 1250/1250 [2:14:57<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Train Loss: 1.3777\n",
      "Val AUC: 0.5229 | Sensitivity: 0.6567 | Specificity: 0.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████| 1250/1250 [19:54<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Train Loss: 1.4018\n",
      "Val AUC: 0.5436 | Sensitivity: 1.0000 | Specificity: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████| 1250/1250 [7:04:29<00:00, 20.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Train Loss: 1.4028\n",
      "Val AUC: 0.5039 | Sensitivity: 0.1791 | Specificity: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|███████████████████████████| 1250/1250 [33:34<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n",
      "Train Loss: 1.4096\n",
      "Val AUC: 0.4974 | Sensitivity: 0.3582 | Specificity: 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████| 1250/1250 [33:48<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n",
      "Train Loss: 1.3899\n",
      "Val AUC: 0.5911 | Sensitivity: 0.8060 | Specificity: 0.2897\n",
      "✅ Saved new best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████████████████████| 1250/1250 [59:17<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10\n",
      "Train Loss: 1.3836\n",
      "Val AUC: 0.4417 | Sensitivity: 0.6269 | Specificity: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████| 1250/1250 [1:02:35<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11\n",
      "Train Loss: 1.3840\n",
      "Val AUC: 0.4181 | Sensitivity: 0.8507 | Specificity: 0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████████████████████| 1250/1250 [59:21<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12\n",
      "Train Loss: 1.4102\n",
      "Val AUC: 0.5047 | Sensitivity: 0.2537 | Specificity: 0.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████████████████████| 1250/1250 [59:31<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13\n",
      "Train Loss: 1.4643\n",
      "Val AUC: 0.5413 | Sensitivity: 0.6567 | Specificity: 0.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████████████████████| 1250/1250 [57:07<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14\n",
      "Train Loss: 1.4048\n",
      "Val AUC: 0.5614 | Sensitivity: 1.0000 | Specificity: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████████████████████| 1250/1250 [57:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15\n",
      "Train Loss: 1.3989\n",
      "Val AUC: 0.5482 | Sensitivity: 0.8657 | Specificity: 0.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████████████████████| 1250/1250 [58:22<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16\n",
      "Train Loss: 1.4085\n",
      "Val AUC: 0.4919 | Sensitivity: 0.7313 | Specificity: 0.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████| 1250/1250 [2:36:01<00:00,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17\n",
      "Train Loss: 1.4094\n",
      "Val AUC: 0.5052 | Sensitivity: 0.1343 | Specificity: 0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|███████████████████████| 1250/1250 [14:02:44<00:00, 40.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18\n",
      "Train Loss: 1.4067\n",
      "Val AUC: 0.5220 | Sensitivity: 0.8507 | Specificity: 0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████████████████████| 1250/1250 [36:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19\n",
      "Train Loss: 1.4097\n",
      "Val AUC: 0.5566 | Sensitivity: 0.1940 | Specificity: 0.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████████████████████| 1250/1250 [45:18<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20\n",
      "Train Loss: 1.4274\n",
      "Val AUC: 0.5015 | Sensitivity: 1.0000 | Specificity: 0.0071\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "# --------------------\n",
    "# Model\n",
    "# --------------------\n",
    "model = get_model().to(device)\n",
    "\n",
    "# --------------------\n",
    "# Handle class imbalance\n",
    "# --------------------\n",
    "train_df = pd.read_csv(\"../data/processed/train_small.csv\")\n",
    "\n",
    "pos = train_df[\"Pneumonia\"].sum()\n",
    "neg = len(train_df) - pos\n",
    "\n",
    "pos_weight = torch.tensor(neg / pos, dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# --------------------\n",
    "# Optimizer\n",
    "# --------------------\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# --------------------\n",
    "# Metrics\n",
    "# --------------------\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_bin).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return auc, sensitivity, specificity\n",
    "\n",
    "# --------------------\n",
    "# Training loop\n",
    "# --------------------\n",
    "num_epochs = 20\n",
    "best_auc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        imgs, labels = imgs.to(device), labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs).squeeze(1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.float().to(device)\n",
    "            outputs = model(imgs).squeeze(1)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(probs.cpu().numpy())\n",
    "\n",
    "    auc, sens, spec = compute_metrics(np.array(all_labels), np.array(all_preds))\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val AUC: {auc:.4f} | Sensitivity: {sens:.4f} | Specificity: {spec:.4f}\")\n",
    "\n",
    "    # ---- Save best model ----\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        torch.save(model.state_dict(), \"../results/best_model.pt\")\n",
    "        print(\"✅ Saved new best model\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb04e2-a068-4a25-87da-41bdcf58f35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chest-xray)",
   "language": "python",
   "name": "chest-xray-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
